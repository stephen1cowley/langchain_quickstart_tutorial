{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"book.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClashEval : Quantifying the tug-of-war between an\n",
      "LLMâ€™s internal prior and external evidence\n",
      "Kevin W\n",
      "{'source': 'book.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:100])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Does GPT-4o have any bias?',\n",
       " 'context': [Document(page_content='5 Discussion\\nTheClashEval benchmark dataset and evaluations provide novel insights into how LLMs arbitrate\\nbetween their own internal knowledge and contextual information when the two are in conflict.\\nA key finding is that even the most advanced LLMs like GPT-4o exhibit a strong context bias,\\noverriding their own correct prior knowledge over 60% of the time when presented with incorrect\\ninformation in the retrieved documents. However, this bias is not absolute - the degree to which\\nthe retrieved content deviates from truth negatively correlates with the context preference rate.\\nInterestingly, each LLM exhibits a different prior distribution over truthfulness across domains, such\\nthat the same perturbation level affects each model differently. For instance, for a given magnitude\\nof deviation, Claude Opus adheres to incorrect contextual information 30% less often than GPT-4o.\\nWhile GPT-4o achieves state-of-the-art results on general-purpose tasks, it exhibits higher context', metadata={'page': 8, 'source': 'book.pdf'}),\n",
       "  Document(page_content='5 Discussion\\nTheClashEval benchmark dataset and evaluations provide novel insights into how LLMs arbitrate\\nbetween their own internal knowledge and contextual information when the two are in conflict.\\nA key finding is that even the most advanced LLMs like GPT-4o exhibit a strong context bias,\\noverriding their own correct prior knowledge over 60% of the time when presented with incorrect\\ninformation in the retrieved documents. However, this bias is not absolute - the degree to which\\nthe retrieved content deviates from truth negatively correlates with the context preference rate.\\nInterestingly, each LLM exhibits a different prior distribution over truthfulness across domains, such\\nthat the same perturbation level affects each model differently. For instance, for a given magnitude\\nof deviation, Claude Opus adheres to incorrect contextual information 30% less often than GPT-4o.\\nWhile GPT-4o achieves state-of-the-art results on general-purpose tasks, it exhibits higher context', metadata={'page': 8, 'source': 'book.pdf'}),\n",
       "  Document(page_content='drug dosages and news. Each modified fact is replaced in the original retrieved text. Then, both the\\nquestion and context are posed to GPT-4, from which the answers, along with the log probabilities of\\nthe output tokens, are collected.\\n4 Results\\nModel Chosen Prior Correct Context Correct\\nClaude OpusPrior 0.585 (0.550, 0.619) 0.042 (0.027, 0.058)\\nContext 0.313 (0.282, 0.346) 0.901 (0.879, 0.923)\\nNeither 0.102 (0.082, 0.125) 0.057 (0.040, 0.075)\\nClaude SonnetPrior 0.436 (0.403, 0.469) 0.051 (0.037, 0.067)\\nContext 0.401 (0.374, 0.434) 0.881 (0.859, 0.903)\\nNeither 0.163 (0.138, 0.186) 0.068 (0.052, 0.086)\\nGemini 1.5Prior 0.388 (0.362, 0.416) 0.074 (0.058, 0.091)\\nContext 0.490 (0.461, 0.521) 0.860 (0.838, 0.881)\\nNeither 0.122 (0.103, 0.143) 0.066 (0.051, 0.082)\\nGPT-4oPrior 0.327 (0.293, 0.358) 0.041 (0.027, 0.056)\\nContext 0.608 (0.571, 0.643) 0.903 (0.881, 0.923)\\nNeither 0.065 (0.047, 0.083) 0.056 (0.040, 0.072)\\nGPT-3.5Prior 0.237 (0.213, 0.263) 0.057 (0.043, 0.072)', metadata={'page': 5, 'source': 'book.pdf'}),\n",
       "  Document(page_content='drug dosages and news. Each modified fact is replaced in the original retrieved text. Then, both the\\nquestion and context are posed to GPT-4, from which the answers, along with the log probabilities of\\nthe output tokens, are collected.\\n4 Results\\nModel Chosen Prior Correct Context Correct\\nClaude OpusPrior 0.585 (0.550, 0.619) 0.042 (0.027, 0.058)\\nContext 0.313 (0.282, 0.346) 0.901 (0.879, 0.923)\\nNeither 0.102 (0.082, 0.125) 0.057 (0.040, 0.075)\\nClaude SonnetPrior 0.436 (0.403, 0.469) 0.051 (0.037, 0.067)\\nContext 0.401 (0.374, 0.434) 0.881 (0.859, 0.903)\\nNeither 0.163 (0.138, 0.186) 0.068 (0.052, 0.086)\\nGemini 1.5Prior 0.388 (0.362, 0.416) 0.074 (0.058, 0.091)\\nContext 0.490 (0.461, 0.521) 0.860 (0.838, 0.881)\\nNeither 0.122 (0.103, 0.143) 0.066 (0.051, 0.082)\\nGPT-4oPrior 0.327 (0.293, 0.358) 0.041 (0.027, 0.056)\\nContext 0.608 (0.571, 0.643) 0.903 (0.881, 0.923)\\nNeither 0.065 (0.047, 0.083) 0.056 (0.040, 0.072)\\nGPT-3.5Prior 0.237 (0.213, 0.263) 0.057 (0.043, 0.072)', metadata={'page': 5, 'source': 'book.pdf'})],\n",
       " 'answer': 'Yes, GPT-4o exhibits a strong context bias. It overrides its own correct prior knowledge over 60% of the time when presented with incorrect information in the retrieved documents. This bias is not absolute and varies depending on the degree of deviation from the truth in the retrieved content.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"Does GPT-4o have any bias?\"})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Discussion\n",
      "TheClashEval benchmark dataset and evaluations provide novel insights into how LLMs arbitrate\n",
      "between their own internal knowledge and contextual information when the two are in conflict.\n",
      "A key finding is that even the most advanced LLMs like GPT-4o exhibit a strong context bias,\n",
      "overriding their own correct prior knowledge over 60% of the time when presented with incorrect\n",
      "information in the retrieved documents. However, this bias is not absolute - the degree to which\n",
      "the retrieved content deviates from truth negatively correlates with the context preference rate.\n",
      "Interestingly, each LLM exhibits a different prior distribution over truthfulness across domains, such\n",
      "that the same perturbation level affects each model differently. For instance, for a given magnitude\n",
      "of deviation, Claude Opus adheres to incorrect contextual information 30% less often than GPT-4o.\n",
      "While GPT-4o achieves state-of-the-art results on general-purpose tasks, it exhibits higher context\n"
     ]
    }
   ],
   "source": [
    "print(results[\"context\"][0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
